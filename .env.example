# Copy this file to ".env" and fill in the values.
# IMPORTANT: Do NOT commit ".env" to git. Commit only ".env.example".
#
# Quick start:
#   cp .env.example .env
#   # edit .env
#   python -m src.chat_cli --component pump
#
# The CLI loads ".env" automatically (or pass --env-file path/to/file).

# Choose the LLM backend:
#   - openai_compat : OpenAI (api.openai.com) or any OpenAI-compatible gateway
#   - ollama        : local Ollama instance
#   - (leave empty) : manual mode (no LLM)
LLM_MODE=openai_compat

# -------------------------
# OpenAI / OpenAI-compatible
# -------------------------
# Use either OPENAI_API_KEY or LLM_API_KEY (both supported)
OPENAI_API_KEY=sk-your_key_here
# LLM_API_KEY=sk-your_key_here

# Model name for your account/gateway
LLM_MODEL=gpt-4o-mini

# Optional: override the API base URL (defaults to https://api.openai.com)
# Examples:
#   LLM_BASE_URL=https://api.openai.com
#   LLM_BASE_URL=http://localhost:8000
#   OPENAI_BASE_URL=http://localhost:8000
# LLM_BASE_URL=https://api.openai.com

# -------------
# Ollama (local)
# -------------
# LLM_MODE=ollama
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.1

# Optional: explicitly point to the dotenv file (CLI also supports --env-file)
# LLM_ENV_FILE=.env
